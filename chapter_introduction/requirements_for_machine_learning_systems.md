## 机器学习系统的需求
![机器学习框架](../img/ch01/framework_position.svg)
:width:`600px`
:label:`framework_position`

为了支持日益增长的机器学习应用，开发者普遍需要依赖机器学习系统（如 :numref:`framework_position`所示）。在设计这种系统的过程中，人们总结出了以下几个设计需求：

-   **支持多种神经网络：**
    深度学习的崛起使得神经网络成为了机器学习应用的核心。不同的应用具有多种数据形态和学习目标，因此人们设计出了不同的神经网络，例如，卷积神经网络（Convolutional
    Neural Networks），图神经网络（Graph Neural
    Networks），自注意力神经网络（Self-attention Neural
    Networks）等等。这些不同的神经网络需要一个共同的系统软件来进行开发。

-   **支持自动微分：**
    神经网络模型的核心计算需求是：系统需要利用数据、标注（Label）和目标损失函数（Loss
    Function）计算梯度（Gradients），并将梯度用以更新神经网络参数。这其中的挑战是如何让系统对于各式各样的神经网络都能**自动化**推导出梯度的计算方法，这个推导过程往往被称之为自动微分。

-   **支持数据管理和处理：**
    机器学习的核心是数据，这其中不仅包括训练、评估和测试数据集，还包括训练后产生的模型参数（Checkpoint），以及训练过程中产生的调试数据（Debugging
    Data）。为了方便这些数据快速导入机器学习框架，我们需要框架本身支持不同类型的数据，以及进行高效的数据处理（如：数据增强和数据清洗）。

-   **支持模型的训练和部署：**
    为了让机器学习模型达到最佳的性能，人们需要使用各种优化方法（例如Mini-Batch
    SGD和其变种）来迭代计算梯度，最终模型的性能达到令开发者满意的状态（该过程称为训练）。同时，根据应用的要求，训练好的模型也需要部署到各种计算设备中，以提供模型推理服务（Inference）。

-   **高效使用计算加速器：**
    神经网络的相关计算可以被表达成矩阵计算，而这一类计算可以被计算加速器（如GPU）极大地加速。因此，机器学习框架需要具备高效利用加速器的能力。

-   **分布式计算：**
    随着数据量的增大和应用的复杂度上升，人们正设计出与之相对应的大型深度神经网络。这一类神经网络往往需要大量的内存来存储参数。同时它们也需要大量的加速器从而实现计算的加速。因此，机器学习框架需要具备分布式执行的能力。

在设计机器学习系统之初，开发者曾尝试通过传统的**神经网络开发库**（如Theano和Caffe）、以及**大数据计算框架**（如Apache
Spark和Google
Pregel）等方式来达到以上设计目标。可是他们发现（如 :numref:`comparison_of_ml_frameworks`所示），
神经网络库虽然提供了神经网络开发、自动微分和加速器的支持，但是其缺乏管理和处理大型数据集、模型部署和分布式执行的能力，使得其无法满足产品级机器学习应用的开发。
此外，虽然大数据计算框架具有成熟的分布式执行和数据管理能力，但是其缺乏对神经网络、自动微分和加速器的支持，使得其并不适合开发以神经网络为核心的机器学习应用。因此，业界从头设计出了包括MindSpore、PaddlePaddle、TensorFlow，PyTorch等一系列机器学习框架。

:机器学习框架和相关系统的比较

|              | 神经网络 | 自动微分 | 数据管理 | 训练和部署 | 加速器 | 分布式 |
|:-: |:-:| :-: |:-:|:-: |:-:|:-:|
| 神经网络库 | 是      | 是      | 否            | 否        | 是    | 否    |
| 大数据框架 | 否      | 否      | 是            | 否        | 否    | 是    |
| 机器学习框架 | 是      | 是      | 是            | 是        | 是    | 是    |
:label:`comparison_of_ml_frameworks`